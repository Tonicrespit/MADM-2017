{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de fraude\n",
    "---\n",
    "Esta parte de la evaluación consiste en realizar un modelo de predicción de fraude.\n",
    "\n",
    "El set de datos està en `data/fraud/creditcard_train.csv`\n",
    "\n",
    "La evaluación es tipo *datathon* de forma que las notas se calcularán en base a:\n",
    "\n",
    "1. Al ranking de métricas de los modelos (80%)\n",
    "2. Legibilidad y presentación del código (20%)\n",
    "\n",
    "La forma de entrega será generar un fichero csv en formato a partir de las predicciones realizadas sobre el fichero `data/fraud/creditcard_test.csv`.\n",
    "\n",
    "| IdObservación | clase_predicha | probabilidad_clase_1 |\n",
    "| ------------- | ------------- | ------------- |\n",
    "|00001|True|0.6398|\n",
    "|00002|True|0.5892|\n",
    "|00003|False|0.2163|\n",
    "\n",
    "EL fichero resultante tiene que tener por nombre `inicialapellido_test.csv` y se tiene que enviar por email a:\n",
    "\n",
    "datathonuib@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis descriptivo básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/fraud/creditcard_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la columna **Index** pues no ofrece información, además ya la estructura de data frame de **Pandas** ya proporciona dicha información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticos básicos del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tabla anterior, tenemos información como la media, la desviación típica, el valor mínimo, máximo y los cuartiles para tener una primera aproximación sobre los datos que se van a manejar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa de calor de correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting and showing correlation matrix\n",
    "corr = df_train.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=0.3, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar del mapa de calor anterior, no existen correlaciones demasiado elevadas entre las variables. De hecho, hay una gran parte de variables que tienen una correlación practicamente nula. \n",
    "Debido a ello, no tendría sentido aplicar **Análisis de componentes principales (PCA)** para reducir la dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution = df_train['Class'].value_counts()\n",
    "class_distribution / sum(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos encontramos ante un problema desbalanceado, ya que solo un ~5% de los datos pertenecen a la clase que queremos predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, utilizaremos una serie de modelos estadísticos donde a la postre los compararemos mediante una serie de métricas tales como **AUC** o **ROC** que nos permitirán escoger el mejor modelo.\n",
    "\n",
    "Debido a que disponemos un conjunto de datos de prueba que no contiene el valor real de la variable respuesta, utilizaremos el conjunto de entrenamiento para realizar las pruebas en primera instancia y obtener una aproximación del error.\n",
    "\n",
    "Una vez elegido el mejor modelo, utilizaremos el conjunto de prueba real sobre el que deseamos realizar la predicción.\n",
    "\n",
    "Los modelos elegidos son:\n",
    "\n",
    "* Regresión logística\n",
    "* Random Forest\n",
    "* Boosting\n",
    "\n",
    "Al trabajar con datos desbalanceados se tendrán que aplicar algunas correcciones para los métodos de regresión logística y de random forest, pero esto no será necesario para Boosting ya que por su propia naturaleza funciona bien en estos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "rnd_seed = 123\n",
    "\n",
    "df = df_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis=1), \n",
    "                                                    df.Class, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=rnd_seed)\n",
    "df_test = pd.read_csv('data/fraud/creditcard_test.csv')\n",
    "df_test = df_test.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como calcular las estadísticas de cada clasificador se hace del mismo modo, se ha escrito una función. Esta función recibe dos parámetros:\n",
    "- `y_true`: Target que queremos predecir.\n",
    "- `y_proba`: Para cada observación, probabilidad que asigna nuestro predictor al target que queremos predecir.\n",
    "\n",
    "A partir de estos dos parámetros la función va a dibujar la curva AUC-ROC y la relación entre precisión y _recall_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotStats(y_true, y_proba):\n",
    "    fpr, tpr, thre = roc_curve(y_true, y_proba[:, 1])\n",
    "    prec, rec, thre = precision_recall_curve(y_true=y_true, probas_pred=y_proba[:,1])\n",
    "    roc_auc = roc_auc_score(y_true, y_proba[:, 1])\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(thre, prec[:-1], label='precision')\n",
    "    plt.plot(thre, rec[:-1], label='recall')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Threshold')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, label='AUC = {a}'.format(a=round(roc_auc, 3)))\n",
    "    plt.plot([0, 1], '--', c='black', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, también se puede automatizar el envío de los resultados para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_output(modelo, df_test, file_prefix):\n",
    "    clases = modelo.predict(df_test)\n",
    "    probas = modelo.predict_proba(df_test)\n",
    "    results = {\n",
    "        \"idObservación\": df_test.index,\n",
    "        \"clase_predicha\": clases,\n",
    "        \"probabilidad_clase_1\": probas[:, 1]\n",
    "    }\n",
    "    df = pd.DataFrame(data = results)\n",
    "    df[[\"idObservación\", \"clase_predicha\", \"probabilidad_clase_1\"]].to_csv('data/fraud/' + file_prefix + '_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=rnd_seed, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante especificar el argumento `class_weight='balanced'` para que la librería se encargue de ajustar el peso de las clases de forma inversamente proporcional a `n_samples / (n_classes * np.bincount(y))`.\n",
    "\n",
    "Como cosecuencia, nuestro modelo tendrá un _accuracy_ menor, pero va a mejorar su predicción fuera de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el conjunto de test que hemos creado (`X_test` y `y_test`) vamos a simular la precisión que tendría nuestro modelo fuera de la muestra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = logreg.predict_proba(X_test)\n",
    "plotStats(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparar_output(logreg, df_test, 'acrespijherreroLR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.tree            import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'max_depth': range(1, 10),\n",
    "#           'min_samples_split': range(2, 20, 2),\n",
    "#           'min_samples_leaf': range(2, 40, 2)}\n",
    "\n",
    "# classifier = RandomForestClassifier(random_state=rnd_seed, class_weight='balanced')\n",
    "# randomForest = GridSearchCV(estimator=classifier, param_grid=params, cv=5, scoring='roc_auc')\n",
    "# randomForest.fit(X_train, y_train)\n",
    "# print(randomForest.best_params_)\n",
    "# Output: {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
    "\n",
    "randomForest = RandomForestClassifier(random_state=rnd_seed, class_weight='balanced', \n",
    "                                      max_depth = 9, min_samples_leaf = 2, min_samples_split = 2)\n",
    "randomForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randomForest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = randomForest.predict_proba(X_test)\n",
    "plotStats(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparar_output(randomForest, df_test, 'acrespijherreroRF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'max_depth': range(1, 10),\n",
    "#           'min_samples_split': range(2, 20, 2),\n",
    "#           'min_samples_leaf': range(2, 40, 2)\n",
    "#          }\n",
    "\n",
    "# classifier = DecisionTreeClassifier()\n",
    "# decisionTree = GridSearchCV(estimator=classifier, param_grid=params, cv=5, scoring='roc_auc')\n",
    "# decisionTree.fit(X_train, y_train)\n",
    "# print(decisionTree.best_params_)\n",
    "# Output: {'max_depth': 2, 'min_samples_leaf': 16, 'min_samples_split': 2}\n",
    "\n",
    "decisionTree = DecisionTreeClassifier(random_state=rnd_seed, class_weight='balanced',\n",
    "                                      max_depth = 2, min_samples_leaf = 16, min_samples_split = 2)\n",
    "decisionTree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decisionTree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = decisionTree.predict_proba(X_test)\n",
    "plotStats(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparar_output(decisionTree, df_test, 'acrespijherreroDT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting + Log. Reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=rnd_seed, class_weight='balanced')\n",
    "boostedLogReg = AdaBoostClassifier(logreg, random_state = rnd_seed)\n",
    "boostedLogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = boostedLogReg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = boostedLogReg.predict_proba(X_test)\n",
    "plotStats(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparar_output(boostedLogReg, df_test, 'acrespijherreroBLR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
